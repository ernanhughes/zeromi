{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ff508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the absolute path to the base directory (one level up from notebook dir)\n",
    "BASE_DIR = Path(__file__).resolve().parent.parent if \"__file__\" in globals() else Path.cwd().parent\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# Now you can import directly\n",
    "from zeromodel import ZeroModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec797084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ernan\\Project\\zeromodel\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "2025-08-11 19:37:36,631 - zeromodel.core - DEBUG - Initializing ZeroModel with metrics: ['uncertainty', 'margin', 'disagreement', 'novelty', 'energy', 'inv_conf'], config: {'use_duckdb': False, 'duckdb_bypass_threshold': 0.5, 'precision': 8, 'normalize_inputs': True, 'nonlinearity_handling': 'auto', 'cache_preprocessed_vpm': True, 'max_cached_tasks': 100, 'default_output_precision': 'float32'}\n",
      "2025-08-11 19:37:36,646 - zeromodel.duckdb_adapter - DEBUG - DuckDB virtual_index table created with 6 metrics.\n",
      "2025-08-11 19:37:36,647 - zeromodel.normalizer - DEBUG - Initializing DynamicNormalizer for 6 metrics\n",
      "2025-08-11 19:37:36,648 - zeromodel.normalizer - INFO - Normalizer initialized with alpha=0.10 for metrics: ['uncertainty', 'margin', 'disagreement', 'novelty', 'energy', 'inv_conf']\n",
      "2025-08-11 19:37:36,649 - zeromodel.vpm.encoder - DEBUG - VPMEncoder initialized with default output precision: float32\n",
      "2025-08-11 19:37:36,649 - zeromodel.core - INFO - ZeroModel initialized with 6 metrics. Default output precision: float32.\n",
      "2025-08-11 19:37:36,649 - zeromodel.core - INFO - Preparing ZeroModel with data shape (53, 6), query: '\n",
      "        SELECT * FROM virtual_index\n",
      "        ORDER BY uncertainty DESC, margin DESC, disagreement DESC, novelty DESC\n",
      "        ', nonlinearity_hint: auto\n",
      "2025-08-11 19:37:36,650 - zeromodel.normalizer - DEBUG - Processing update with matrix shape (53, 6)\n",
      "2025-08-11 19:37:36,652 - zeromodel.normalizer - DEBUG - Initialized uncertainty range: [0.0046, 0.4564]\n",
      "2025-08-11 19:37:36,654 - zeromodel.normalizer - DEBUG - Initialized margin range: [0.0091, 0.9092]\n",
      "2025-08-11 19:37:36,655 - zeromodel.normalizer - DEBUG - Initialized disagreement range: [0.0000, 1.0000]\n",
      "2025-08-11 19:37:36,656 - zeromodel.normalizer - DEBUG - Initialized novelty range: [0.0000, 1.0000]\n",
      "2025-08-11 19:37:36,657 - zeromodel.normalizer - DEBUG - Initialized energy range: [0.0000, 1.0000]\n",
      "2025-08-11 19:37:36,658 - zeromodel.normalizer - DEBUG - Initialized inv_conf range: [0.0023, 0.4421]\n",
      "2025-08-11 19:37:36,659 - zeromodel.normalizer - INFO - Updated ranges using 53 documents\n",
      "2025-08-11 19:37:36,660 - zeromodel.normalizer - DEBUG - Normalizing matrix with shape (53, 6)\n",
      "2025-08-11 19:37:36,661 - zeromodel.normalizer - DEBUG - Normalized 'uncertainty' using range [0.004552, 0.456428]\n",
      "2025-08-11 19:37:36,662 - zeromodel.normalizer - DEBUG - Normalized 'margin' using range [0.009103, 0.909228]\n",
      "2025-08-11 19:37:36,663 - zeromodel.normalizer - DEBUG - Normalized 'disagreement' using range [0.000000, 1.000000]\n",
      "2025-08-11 19:37:36,664 - zeromodel.normalizer - DEBUG - Normalized 'novelty' using range [0.000000, 1.000000]\n",
      "2025-08-11 19:37:36,665 - zeromodel.normalizer - DEBUG - Normalized 'energy' using range [0.000000, 1.000000]\n",
      "2025-08-11 19:37:36,665 - zeromodel.normalizer - DEBUG - Normalized 'inv_conf' using range [0.002276, 0.442084]\n",
      "2025-08-11 19:37:36,667 - zeromodel.normalizer - INFO - Normalized 53 documents\n",
      "2025-08-11 19:37:36,668 - zeromodel.feature_engineer - INFO - Auto hint added 5 features (expected ~5 when n>=3).\n",
      "2025-08-11 19:37:36,669 - zeromodel.core - INFO - Feature engineering added 5 new metrics (total now 11)\n",
      "2025-08-11 19:37:36,671 - zeromodel.core - INFO - VPM-IMG written to c:\\Users\\ernan\\Project\\zeromodel\\notebooks\\zeromodel_canonical.ppm.png\n",
      "2025-08-11 19:37:36,672 - zeromodel.core - INFO - ZeroModel preparation complete. VPM-IMG is ready.\n",
      "2025-08-11 19:37:36,672 - zeromodel.timing - DEBUG - Timer ZeroModel.prepare completed in 23.056 ms\n",
      "2025-08-11 19:37:36,673 - zeromodel.vpm.logic - DEBUG - Denormalizing VPM to dtype <class 'numpy.float32'> (assume_normalized=True)\n",
      "2025-08-11 19:37:36,674 - zeromodel.vpm.encoder - DEBUG - Encoded VPM: shape=(53, 4, 3) dtype=float32 precision=float32\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "`ptp` was removed from the ndarray class in NumPy 2.0. Use np.ptp(arr, ...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[32m    123\u001b[39m title = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: VPM-style tile (top-left concentrates task signal)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m _ = \u001b[43mmake_and_show_vpm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mmake_and_show_vpm\u001b[39m\u001b[34m(S, metric_names, title, task_sql, nonlinearity_hint)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# visualize R channel approx by summing RGB\u001b[39;00m\n\u001b[32m    100\u001b[39m img = vpm.sum(axis=\u001b[32m2\u001b[39m).astype(np.float32)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m img = (img - img.min()) / (\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptp\u001b[49m() + \u001b[32m1e-9\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# plot\u001b[39;00m\n\u001b[32m    104\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m,\u001b[32m6\u001b[39m))\n",
      "\u001b[31mAttributeError\u001b[39m: `ptp` was removed from the ndarray class in NumPy 2.0. Use np.ptp(arr, ...) instead."
     ]
    }
   ],
   "source": [
    "# ZeroModel Visual AI demo with offline datasets\n",
    "# Works fully offline with scikit-learn. If zeromodel is importable, uses it;\n",
    "# otherwise builds a mock VPM so you can still see the top-left concentration.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# ---- choose dataset: \"iris\" | \"wine\" | \"cancer\" | \"xor\"\n",
    "DATASET = \"iris\"\n",
    "\n",
    "# ---- load data\n",
    "if DATASET == \"iris\":\n",
    "    ds = load_iris()\n",
    "    X, y = ds.data, ds.target\n",
    "    name = \"Iris\"\n",
    "elif DATASET == \"wine\":\n",
    "    ds = load_wine()\n",
    "    X, y = ds.data, ds.target\n",
    "    name = \"Wine\"\n",
    "elif DATASET == \"cancer\":\n",
    "    ds = load_breast_cancer()\n",
    "    X, y = ds.data, ds.target\n",
    "    name = \"Breast Cancer\"\n",
    "elif DATASET == \"xor\":\n",
    "    # hard nonlinear: 2 informative features laid out XOR-like\n",
    "    X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, \n",
    "                               n_redundant=0, n_clusters_per_class=1, class_sep=1.0, random_state=7)\n",
    "    name = \"Synthetic XOR\"\n",
    "else:\n",
    "    raise ValueError(\"Unknown DATASET\")\n",
    "\n",
    "# ---- split & scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42, stratify=y)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "# ---- two simple models so we can measure uncertainty & disagreement\n",
    "clf1 = LogisticRegression(max_iter=500, multi_class=\"auto\", solver=\"lbfgs\", n_jobs=None).fit(X_train_s, y_train)\n",
    "clf2 = RandomForestClassifier(n_estimators=200, random_state=0).fit(X_train_s, y_train)\n",
    "\n",
    "proba1 = clf1.predict_proba(X_test_s)\n",
    "proba2 = clf2.predict_proba(X_test_s)\n",
    "\n",
    "# ---- per-sample metrics in [0,1] for a VPM \"documents x metrics\"\n",
    "# 1) Uncertainty: 1 - confidence (max prob) from model 1\n",
    "uncertainty = 1.0 - proba1.max(axis=1)\n",
    "\n",
    "# 2) Margin: difference between top-1 and top-2 probs (smaller = harder)\n",
    "def top2_margin(P):\n",
    "    sortp = np.sort(P, axis=1)\n",
    "    return (sortp[:, -1] - sortp[:, -2]) if P.shape[1] >= 2 else sortp[:, -1]\n",
    "margin = 1.0 - top2_margin(proba1)  # invert so \"higher = more interesting\"\n",
    "\n",
    "# 3) Disagreement: Jensen-Shannon-ish divergence proxy between models (cheap)\n",
    "eps = 1e-12\n",
    "P = np.clip(proba1, eps, 1.0); Q = np.clip(proba2, eps, 1.0)\n",
    "M = 0.5*(P+Q)\n",
    "kl = (P*np.log(P/M)).sum(axis=1) + (Q*np.log(Q/M)).sum(axis=1)\n",
    "disagreement = (kl - kl.min()) / (np.ptp(kl) + 1e-12)\n",
    "\n",
    "# 4) Novelty: distance to nearest training neighbor (higher = more novel)\n",
    "nn = NearestNeighbors(n_neighbors=1).fit(X_train_s)\n",
    "dists, _ = nn.kneighbors(X_test_s, n_neighbors=1)\n",
    "novelty = (dists[:,0] - dists.min()) / (np.ptp(dists) + 1e-12)\n",
    "\n",
    "# 5) Feature energy: L2 norm (scaled), acts like a “size/strength” proxy\n",
    "energy = np.linalg.norm(X_test_s, axis=1)\n",
    "energy = (energy - energy.min())/(np.ptp(energy) + 1e-12)\n",
    "\n",
    "# 6) Ensemble confidence (max prob from averaged probs), invert for “interesting”\n",
    "proba_avg = 0.5*(proba1 + proba2)\n",
    "conf_inv = 1.0 - proba_avg.max(axis=1)\n",
    "\n",
    "# stack metrics (N_docs x N_metrics)\n",
    "metric_names = [\"uncertainty\",\"margin\",\"disagreement\",\"novelty\",\"energy\",\"inv_conf\"]\n",
    "S = np.vstack([uncertainty, margin, disagreement, novelty, energy, conf_inv]).T  # shape (N,6)\n",
    "\n",
    "# safe clip\n",
    "S = np.clip(S, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def make_and_show_vpm(S, metric_names, title, task_sql=None, nonlinearity_hint=\"auto\"):\n",
    "    zm = ZeroModel(metric_names=metric_names)\n",
    "    if task_sql is None:\n",
    "        # push AI-ish/uncertain items to top-left by default\n",
    "        task_sql = \"\"\"\n",
    "        SELECT * FROM virtual_index\n",
    "        ORDER BY uncertainty DESC, margin DESC, disagreement DESC, novelty DESC\n",
    "        \"\"\"\n",
    "    zm.prepare(S, task_sql, nonlinearity_hint=nonlinearity_hint)\n",
    "    vpm = zm.encode()  # (rows, width_pixels, 3)\n",
    "    # visualize R channel approx by summing RGB\n",
    "    img = vpm.sum(axis=2).astype(np.float32)\n",
    "    img = (img - img.min()) / (np.ptp(img) + 1e-9)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(img, aspect='auto', origin='upper', interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"metrics →\")\n",
    "    plt.ylabel(\"documents (sorted) ↓\")\n",
    "    # add metric ticks if not too many\n",
    "    if img.shape[1] <= 12:\n",
    "        plt.xticks(range(len(metric_names)), metric_names, rotation=45, ha='right')\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "    # draw a box around the top-left “critical” patch\n",
    "    h = min(6, img.shape[0]-1)\n",
    "    w = min(2, img.shape[1]-1)\n",
    "    plt.gca().add_patch(plt.Rectangle((-.5, -.5), w, h, fill=False, linewidth=2))\n",
    "    plt.colorbar(shrink=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return img\n",
    "\n",
    "title = f\"{name}: VPM-style tile (top-left concentrates task signal)\"\n",
    "_ = make_and_show_vpm(S, metric_names, title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
