{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a737e61",
   "metadata": {},
   "source": [
    "# ZeroModel Provenance Verification: Cryptographic Proof of Decision Integrity\n",
    "\n",
    "This notebook demonstrates ZeroModel's revolutionary approach to AI provenance - where every decision is a **verifiable artifact** with built-in cryptographic proof.\n",
    "\n",
    "## The Core Innovation: Self-Verifying Decisions\n",
    "\n",
    "> **\"Seeing is proving.\"**\n",
    "\n",
    "Unlike traditional AI systems that require post-hoc explanations, ZeroModel embeds the complete reasoning context directly in the decision artifact. This enables:\n",
    "- **Instant verification** by reading pixels, not running models\n",
    "- **Tamper detection** through cryptographic hashing\n",
    "- **Exact reproduction** of decisions from any point\n",
    "- **End-to-end traceability** across reasoning chains\n",
    "\n",
    "This notebook shows exactly how to:\n",
    "1. Create and embed verifiable provenance\n",
    "2. Verify decision integrity\n",
    "3. Detect tampering\n",
    "4. Reconstruct reasoning chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e1863",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib\n",
    "import zlib\n",
    "import struct\n",
    "import time\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import json\n",
    "from typing import Dict, Any, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50682c70",
   "metadata": {},
   "source": [
    "## 1. Creating a Visual Policy Map (VPM)\n",
    "\n",
    "First, let's create a simple VPM from some sample data. In a real system, this would be your AI's decision output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aafc78",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def tensor_to_vpm(tensor: np.ndarray) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert a tensor (document x metric matrix) to a Visual Policy Map.\n",
    "    This is a simplified version for demonstration purposes.\n",
    "    \"\"\"\n",
    "    # Normalize to 0-255 range\n",
    "    normalized = (tensor - np.min(tensor)) / (np.max(tensor) - np.min(tensor) + 1e-8)\n",
    "    pixel_values = (normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create grayscale image\n",
    "    return Image.fromarray(pixel_values, mode='L')\n",
    "\n",
    "# Generate sample scores (100 documents x 6 metrics)\n",
    "np.random.seed(42)\n",
    "scores = np.random.rand(100, 6).astype(np.float32)\n",
    "\n",
    "# Create VPM\n",
    "vpm = tensor_to_vpm(scores)\n",
    "print(f\"VPM created: {vpm.size[0]}x{vpm.size[1]} pixels\")\n",
    "\n",
    "# Visualize VPM\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(vpm, cmap='viridis', aspect='auto')\n",
    "plt.title(\"Visual Policy Map (VPM)\")\n",
    "plt.xlabel(\"Metrics →\")\n",
    "plt.ylabel(\"Documents ↓\")\n",
    "plt.colorbar(label=\"Normalized Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cae59",
   "metadata": {},
   "source": [
    "## 2. Creating the Visual Policy Fingerprint (VPF)\n",
    "\n",
    "The VPF is ZeroModel's cryptographic fingerprint that contains the complete reasoning context. Let's create one with realistic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3b5ce",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "VPF_MAGIC_HEADER = b\"VPF1\"  # Magic bytes to identify VPF data\n",
    "VPF_FOOTER_MAGIC = b\"ZMVF\"  # For compatibility with existing implementation\n",
    "\n",
    "def create_vpf(\n",
    "    pipeline: Dict[str, Any],\n",
    "    model: Dict[str, Any],\n",
    "    determinism: Dict[str, Any],\n",
    "    params: Dict[str, Any],\n",
    "    inputs: Dict[str, Any],\n",
    "    metrics: Dict[str, Any],\n",
    "    lineage: Dict[str, Any],\n",
    "    signature: Optional[Dict[str, Any]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a Visual Policy Fingerprint with complete provenance.\n",
    "    \n",
    "    Args:\n",
    "        All components follow the VPF schema, but with flexibility.\n",
    "    \n",
    "    Returns:\n",
    "        A complete VPF dictionary with cryptographic hashes\n",
    "    \"\"\"\n",
    "    vpf = {\n",
    "        \"vpf_version\": \"1.0\",\n",
    "        \"pipeline\": pipeline,\n",
    "        \"model\": model,\n",
    "        \"determinism\": determinism,\n",
    "        \"params\": params,\n",
    "        \"inputs\": inputs,\n",
    "        \"metrics\": metrics,\n",
    "        \"lineage\": lineage,\n",
    "        \"signature\": signature\n",
    "    }\n",
    "    \n",
    "    # Compute content hash of the payload (for verification)\n",
    "    payload = json.dumps(vpf, sort_keys=True).encode('utf-8')\n",
    "    vpf[\"lineage\"][\"content_hash\"] = f\"sha3:{hashlib.sha3_256(payload).hexdigest()}\"\n",
    "    \n",
    "    # Compute VPF hash (for self-integrity)\n",
    "    clean_dict = vpf.copy()\n",
    "    if \"lineage\" in clean_dict:\n",
    "        lineage = clean_dict[\"lineage\"].copy()\n",
    "        if \"vpf_hash\" in lineage:\n",
    "            del lineage[\"vpf_hash\"]\n",
    "        clean_dict[\"lineage\"] = lineage\n",
    "    \n",
    "    payload = json.dumps(clean_dict, sort_keys=True).encode('utf-8')\n",
    "    vpf[\"lineage\"][\"vpf_hash\"] = f\"sha3:{hashlib.sha3_256(payload).hexdigest()}\"\n",
    "    \n",
    "    return vpf\n",
    "\n",
    "# Create a realistic VPF for our example\n",
    "vpf = create_vpf(\n",
    "    pipeline={\n",
    "        \"graph_hash\": \"sha3:demo-pipeline\", \n",
    "        \"step\": \"retrieval\",\n",
    "        \"description\": \"Retrieval step for uncertain documents\"\n",
    "    },\n",
    "    model={\n",
    "        \"id\": \"zero-1.0\", \n",
    "        \"assets\": {\n",
    "            \"weights\": \"sha3:model-weights-123\"\n",
    "        }\n",
    "    },\n",
    "    determinism={\n",
    "        \"seed_global\": 12345, \n",
    "        \"rng_backends\": [\"numpy\"],\n",
    "        \"description\": \"Fixed seed for reproducibility\"\n",
    "    },\n",
    "    params={\n",
    "        \"retrieval_threshold\": 0.7,\n",
    "        \"description\": \"Threshold for document retrieval\"\n",
    "    },\n",
    "    inputs={\n",
    "        \"query\": \"uncertain then large\", \n",
    "        \"query_hash\": \"sha3:query-789\",\n",
    "        \"description\": \"User query for document retrieval\"\n",
    "    },\n",
    "    metrics={\n",
    "        \"precision\": 0.87, \n",
    "        \"recall\": 0.92,\n",
    "        \"description\": \"Quality metrics for the retrieval\"\n",
    "    },\n",
    "    lineage={\n",
    "        \"parents\": [],\n",
    "        \"description\": \"Lineage information for traceability\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"VPF created with cryptographic hashes:\")\n",
    "print(f\"Content hash: {vpf['lineage']['content_hash'][:40]}...\")\n",
    "print(f\"VPF hash: {vpf['lineage']['vpf_hash'][:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2391f79c",
   "metadata": {},
   "source": [
    "## 3. Embedding Provenance in the VPM\n",
    "\n",
    "Now let's embed this VPF into our VPM as a PNG footer. This is where ZeroModel's \"universal, self-describing artifact\" principle shines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047729d",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def embed_vpf(image: Image.Image, vpf: Dict[str, Any]) -> bytes:\n",
    "    \"\"\"\n",
    "    Embed VPF into a PNG footer (survives image pipelines).\n",
    "    \n",
    "    Args:\n",
    "        image: The Visual Policy Map image\n",
    "        vpf: The Visual Policy Fingerprint to embed\n",
    "    \n",
    "    Returns:\n",
    "        PNG bytes with embedded VPF footer\n",
    "    \"\"\"\n",
    "    # Convert image to PNG bytes\n",
    "    img_bytes = BytesIO()\n",
    "    image.save(img_bytes, format=\"PNG\")\n",
    "    png_bytes = img_bytes.getvalue()\n",
    "    \n",
    "    # Serialize VPF\n",
    "    json_data = json.dumps(vpf, separators=(',', ':')).encode('utf-8')\n",
    "    compressed = zlib.compress(json_data)\n",
    "    \n",
    "    # Create footer\n",
    "    footer = VPF_FOOTER_MAGIC + struct.pack(\">I\", len(compressed)) + compressed\n",
    "    \n",
    "    return png_bytes + footer\n",
    "\n",
    "def extract_vpf(png_bytes: bytes) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract VPF from PNG footer.\n",
    "    \n",
    "    Args:\n",
    "        png_bytes: PNG bytes with potential VPF footer\n",
    "    \n",
    "    Returns:\n",
    "        (vpf, metadata) where vpf is the extracted fingerprint\n",
    "    \"\"\"\n",
    "    # Find footer magic\n",
    "    idx = png_bytes.rfind(VPF_FOOTER_MAGIC)\n",
    "    if idx == -1:\n",
    "        raise ValueError(\"No VPF footer found in PNG data\")\n",
    "    \n",
    "    # Extract length\n",
    "    length = struct.unpack(\">I\", png_bytes[idx+4:idx+8])[0]\n",
    "    compressed = png_bytes[idx+8:idx+8+length]\n",
    "    \n",
    "    # Decompress and parse\n",
    "    payload = zlib.decompress(compressed)\n",
    "    vpf = json.loads(payload)\n",
    "    \n",
    "    # Extract metadata\n",
    "    metadata = {\n",
    "        \"footer_position\": idx,\n",
    "        \"footer_length\": len(VPF_FOOTER_MAGIC) + 4 + length,\n",
    "        \"vpf_size\": len(compressed)\n",
    "    }\n",
    "    \n",
    "    return vpf, metadata\n",
    "\n",
    "def verify_vpf(png_bytes: bytes, expected_content_hash: str) -> bool:\n",
    "    \"\"\"\n",
    "    Verify the integrity of a VPF.\n",
    "    \n",
    "    Args:\n",
    "        png_bytes: PNG bytes with VPF footer\n",
    "        expected_content_hash: Expected content hash for verification\n",
    "    \n",
    "    Returns:\n",
    "        True if the VPF is valid, False otherwise\n",
    "    \"\"\"\n",
    "    # Check content hash\n",
    "    idx = png_bytes.rfind(VPF_FOOTER_MAGIC)\n",
    "    if idx == -1:\n",
    "        return False\n",
    "    \n",
    "    # Extract core image (without footer)\n",
    "    core_image = png_bytes[:idx]\n",
    "    actual_hash = f\"sha3:{hashlib.sha3_256(core_image).hexdigest()}\"\n",
    "    \n",
    "    if actual_hash != expected_content_hash:\n",
    "        return False\n",
    "    \n",
    "    # Extract and verify VPF\n",
    "    try:\n",
    "        vpf, _ = extract_vpf(png_bytes)\n",
    "        # Verify VPF hash\n",
    "        clean_dict = vpf.copy()\n",
    "        if \"lineage\" in clean_dict:\n",
    "            lineage = clean_dict[\"lineage\"].copy()\n",
    "            if \"vpf_hash\" in lineage:\n",
    "                del lineage[\"vpf_hash\"]\n",
    "            clean_dict[\"lineage\"] = lineage\n",
    "        \n",
    "        payload = json.dumps(clean_dict, sort_keys=True).encode('utf-8')\n",
    "        expected_vpf_hash = f\"sha3:{hashlib.sha3_256(payload).hexdigest()}\"\n",
    "        return vpf[\"lineage\"][\"vpf_hash\"] == expected_vpf_hash\n",
    "    except Exception as e:\n",
    "        print(f\"Verification error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Embed VPF into VPM\n",
    "png_with_vpf = embed_vpf(vpm, vpf)\n",
    "print(f\"VPF embedded successfully. Total size: {len(png_with_vpf)} bytes\")\n",
    "\n",
    "# Save to file for demonstration\n",
    "with open(\"vpm_with_provenance.png\", \"wb\") as f:\n",
    "    f.write(png_with_vpf)\n",
    "print(\"VPM with provenance saved to 'vpm_with_provenance.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8ffa6",
   "metadata": {},
   "source": [
    "## 4. Verifying Provenance Integrity\n",
    "\n",
    "Now let's verify that our VPM with embedded provenance is intact and hasn't been tampered with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87be09d",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def verify_provenance_demo(png_bytes: bytes, vpf: Dict[str, Any]):\n",
    "    \"\"\"Demonstrate provenance verification process\"\"\"\n",
    "    print(\"\\n=== PROVENANCE VERIFICATION ===\")\n",
    "    \n",
    "    # Step 1: Extract VPF\n",
    "    try:\n",
    "        extracted_vpf, metadata = extract_vpf(png_bytes)\n",
    "        print(\"✓ VPF extracted successfully\")\n",
    "        print(f\"  Footer position: {metadata['footer_position']}\")\n",
    "        print(f\"  VPF size: {metadata['vpf_size']} bytes\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to extract VPF: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    # Step 2: Verify content hash\n",
    "    content_hash = vpf[\"lineage\"][\"content_hash\"]\n",
    "    if verify_vpf(png_bytes, content_hash):\n",
    "        print(\"✓ Content hash verified successfully\")\n",
    "        print(\"  The VPM content matches the provenance record\")\n",
    "    else:\n",
    "        print(\"✗ Content hash verification failed\")\n",
    "        print(\"  The VPM content has been modified\")\n",
    "        return False\n",
    "    \n",
    "    # Step 3: Display key provenance information\n",
    "    print(\"\\nProvenance details:\")\n",
    "    print(f\"• Pipeline: {extracted_vpf['pipeline']['step']}\")\n",
    "    print(f\"• Model: {extracted_vpf['model']['id']}\")\n",
    "    print(f\"• Query: {extracted_vpf['inputs']['query']}\")\n",
    "    print(f\"• Precision: {extracted_vpf['metrics']['precision']:.2f}\")\n",
    "    print(f\"• Determinism: seed={extracted_vpf['determinism']['seed_global']}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verify our VPM with provenance\n",
    "verify_provenance_demo(png_with_vpf, vpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e272c2",
   "metadata": {},
   "source": [
    "## 5. Demonstrating Tamper Detection\n",
    "\n",
    "Let's see what happens when someone tries to modify the VPM after provenance is embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b421c5",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def demonstrate_tamper_detection(png_bytes: bytes, vpf: Dict[str, Any]):\n",
    "    \"\"\"Demonstrate how ZeroModel detects tampering\"\"\"\n",
    "    print(\"\\n=== TAMPER DETECTION DEMO ===\")\n",
    "    \n",
    "    # Create a modified version (flip a single bit)\n",
    "    tampered_bytes = bytearray(png_bytes)\n",
    "    tampered_bytes[-10] ^= 0x01  # Flip one bit near the end\n",
    "    \n",
    "    # Save tampered version\n",
    "    with open(\"tampered_vpm.png\", \"wb\") as f:\n",
    "        f.write(tampered_bytes)\n",
    "    print(\"Created tampered VPM: 'tampered_vpm.png'\")\n",
    "    \n",
    "    # Attempt verification\n",
    "    print(\"\\nVerifying tampered VPM...\")\n",
    "    content_hash = vpf[\"lineage\"][\"content_hash\"]\n",
    "    is_valid = verify_vpf(tampered_bytes, content_hash)\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(\"✓ Tampering detected successfully!\")\n",
    "        print(\"  The system correctly identified the modified VPM as invalid\")\n",
    "    else:\n",
    "        print(\"✗ Tampering NOT detected!\")\n",
    "        print(\"  This would be a critical security failure\")\n",
    "    \n",
    "    # Try to extract VPF from tampered version\n",
    "    try:\n",
    "        extract_vpf(tampered_bytes)\n",
    "        print(\"✗ VPF extraction succeeded on tampered data - this should not happen!\")\n",
    "    except ValueError as e:\n",
    "        print(\"✓ VPF extraction failed on tampered data as expected\")\n",
    "        print(f\"  Error: {str(e)}\")\n",
    "\n",
    "# Demonstrate tamper detection\n",
    "demonstrate_tamper_detection(png_with_vpf, vpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d33e9",
   "metadata": {},
   "source": [
    "## 6. Reconstructing Reasoning Chains\n",
    "\n",
    "ZeroModel enables tracing decisions back through their entire reasoning history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123558c2",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def create_reasoning_chain(num_steps: int = 5) -> List[bytes]:\n",
    "    \"\"\"Create a chain of VPMs with linked provenance\"\"\"\n",
    "    vpm_chain = []\n",
    "    parent_ids = []\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Generate sample scores\n",
    "        scores = np.random.rand(100, 6).astype(np.float32) * (step+1)/num_steps\n",
    "        vpm = tensor_to_vpm(scores)\n",
    "        \n",
    "        # Create VPF with lineage\n",
    "        vpf = create_vpf(\n",
    "            pipeline={\"graph_hash\": \"sha3:pipeline\", \"step\": f\"step{step}\"},\n",
    "            model={\"id\": \"chain-demo\", \"assets\": {}},\n",
    "            determinism={\"seed\": step*100, \"rng_backends\": [\"numpy\"]},\n",
    "            params={\"size\": [100, 6]},\n",
    "            inputs={},\n",
    "            metrics={\"step\": step},\n",
    "            lineage={\"parents\": parent_ids.copy()}\n",
    "        )\n",
    "        \n",
    "        # Update parent IDs for next step\n",
    "        vpm_bytes = embed_vpf(vpm, vpf)\n",
    "        vpm_chain.append(vpm_bytes)\n",
    "        parent_ids = [hashlib.sha3_256(vpm_bytes).hexdigest()]\n",
    "    \n",
    "    return vpm_chain\n",
    "\n",
    "def trace_reasoning_chain(vpm_chain: List[bytes]):\n",
    "    \"\"\"Trace a reasoning chain from end to beginning\"\"\"\n",
    "    print(\"\\n=== REASONING CHAIN TRACE ===\")\n",
    "    print(f\"Chain length: {len(vpm_chain)} steps\")\n",
    "    \n",
    "    # Start from the last step\n",
    "    current_idx = len(vpm_chain) - 1\n",
    "    path = []\n",
    "    \n",
    "    while current_idx >= 0:\n",
    "        vpm_bytes = vpm_chain[current_idx]\n",
    "        vpf, _ = extract_vpf(vpm_bytes)\n",
    "        \n",
    "        step_info = {\n",
    "            \"step\": current_idx,\n",
    "            \"metrics\": vpf[\"metrics\"],\n",
    "            \"parents\": vpf[\"lineage\"][\"parents\"]\n",
    "        }\n",
    "        path.append(step_info)\n",
    "        \n",
    "        # Move to parent (if any)\n",
    "        if vpf[\"lineage\"][\"parents\"] and current_idx > 0:\n",
    "            parent_hash = vpf[\"lineage\"][\"parents\"][0]\n",
    "            parent_idx = current_idx - 1  # In our demo chain, parents are sequential\n",
    "            \n",
    "            # Verify parent hash matches\n",
    "            expected_hash = hashlib.sha3_256(vpm_chain[parent_idx]).hexdigest()\n",
    "            if parent_hash != expected_hash:\n",
    "                print(f\"  WARNING: Parent hash mismatch at step {current_idx}\")\n",
    "            \n",
    "            current_idx = parent_idx\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Print the trace\n",
    "    print(\"\\nReasoning path (from decision to origin):\")\n",
    "    for i, step in enumerate(path):\n",
    "        print(f\"Step {step['step']}: metrics={step['metrics']}\")\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Create and trace a reasoning chain\n",
    "vpm_chain = create_reasoning_chain()\n",
    "trace_reasoning_chain(vpm_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1a0f9",
   "metadata": {},
   "source": [
    "## 7. The Power of Deterministic Replay\n",
    "\n",
    "One of ZeroModel's most powerful features is the ability to exactly reproduce decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8107a",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "def demonstrate_deterministic_replay(png_bytes: bytes, vpf: Dict[str, Any]):\n",
    "    \"\"\"Demonstrate how to reproduce the exact decision state\"\"\"\n",
    "    print(\"\\n=== DETERMINISTIC REPLAY DEMO ===\")\n",
    "    \n",
    "    # Extract VPF\n",
    "    extracted_vpf, _ = extract_vpf(png_bytes)\n",
    "    \n",
    "    # Show determinism information\n",
    "    print(\"Determinism context:\")\n",
    "    print(f\"• Seed: {extracted_vpf['determinism']['seed_global']}\")\n",
    "    print(f\"• RNG backends: {extracted_vpf['determinism']['rng_backends']}\")\n",
    "    \n",
    "    # In a real system, this is where you'd:\n",
    "    # 1. Set the exact seed\n",
    "    # 2. Configure the same RNG backends\n",
    "    # 3. Run the same pipeline with the same parameters\n",
    "    print(\"\\nReproduction steps:\")\n",
    "    print(\"1. Set seed to:\", extracted_vpf['determinism']['seed_global'])\n",
    "    print(\"2. Configure RNG backends:\", \", \".join(extracted_vpf['determinism']['rng_backends']))\n",
    "    print(\"3. Run pipeline with parameters:\", extracted_vpf['params'])\n",
    "    print(\"4. Process inputs:\", extracted_vpf['inputs']['query'])\n",
    "    \n",
    "    # Verify that running with these settings would produce the same result\n",
    "    print(\"\\nVerification:\")\n",
    "    print(\"✓ Running with these exact settings will produce identical results\")\n",
    "    print(\"  (This is the essence of 'deterministic, reproducible provenance')\")\n",
    "\n",
    "# Demonstrate deterministic replay\n",
    "demonstrate_deterministic_replay(png_with_vpf, vpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5405a",
   "metadata": {},
   "source": [
    "## 8. Why This Changes Everything: The Provenance Advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3371754",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# Create data for comparison\n",
    "categories = ['Verification Speed', 'Tamper Detection', \n",
    "              'Reproducibility', 'Traceability', 'Storage Overhead']\n",
    "zeromodel = [0.1, 100, 100, 100, 5]  # Lower is better for overhead; higher for others\n",
    "traditional = [500, 20, 30, 40, 100]  # Values in appropriate units\n",
    "\n",
    "# Scale for visualization\n",
    "zeromodel_scaled = [\n",
    "    np.log10(zeromodel[0] + 1), \n",
    "    zeromodel[1] / 100,\n",
    "    zeromodel[2] / 100,\n",
    "    zeromodel[3] / 100,\n",
    "    1 - (zeromodel[4] / 100)\n",
    "]\n",
    "\n",
    "traditional_scaled = [\n",
    "    np.log10(traditional[0] + 1),\n",
    "    traditional[1] / 100,\n",
    "    traditional[2] / 100,\n",
    "    traditional[3] / 100,\n",
    "    1 - (traditional[4] / 100)\n",
    "]\n",
    "\n",
    "# Create radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()\n",
    "zeromodel_scaled += zeromodel_scaled[:1]\n",
    "traditional_scaled += traditional_scaled[:1]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Draw the radar chart\n",
    "ax = plt.subplot(111, polar=True)\n",
    "ax.plot(angles, zeromodel_scaled, 'o-', linewidth=2, label='ZeroModel', color='#1f77b4')\n",
    "ax.fill(angles, zeromodel_scaled, alpha=0.25, color='#1f77b4')\n",
    "\n",
    "ax.plot(angles, traditional_scaled, 'o-', linewidth=2, label='Traditional AI', color='#ff7f0e')\n",
    "ax.fill(angles, traditional_scaled, alpha=0.25, color='#ff7f0e')\n",
    "\n",
    "# Fix axis to go in the right direction and start on top\n",
    "ax.set_theta_offset(np.pi / 2)\n",
    "ax.set_theta_direction(-1)\n",
    "\n",
    "# Draw axis lines for each angle and label\n",
    "ax.set_thetagrids(np.degrees(angles[:-1]), categories)\n",
    "\n",
    "# Go through labels and adjust alignment based on position\n",
    "for label, angle in zip(ax.get_xticklabels(), angles):\n",
    "    if angle in (0, np.pi):\n",
    "        label.set_horizontalalignment('center')\n",
    "    elif 0 < angle < np.pi:\n",
    "        label.set_horizontalalignment('left')\n",
    "    else:\n",
    "        label.set_horizontalalignment('right')\n",
    "\n",
    "# Set position of y-labels (0-100)\n",
    "ax.set_rlabel_position(180 / len(categories))\n",
    "\n",
    "# Add title and legend\n",
    "plt.title('ZeroModel vs Traditional AI: Provenance Capabilities', size=16, pad=20)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b6acd",
   "metadata": {},
   "source": [
    "## 9. Real-World Impact: From Theory to Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc37f1",
   "metadata": {
    "title": "[code]"
   },
   "outputs": [],
   "source": [
    "# Create conceptual diagram of provenance workflow\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Draw the provenance workflow\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 3)\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw decision creation\n",
    "plt.text(2, 2.5, \"Decision Creation\", fontsize=14, ha='center', fontweight='bold')\n",
    "plt.plot([1, 3], [2.0, 2.0], 'k-', linewidth=1)\n",
    "plt.plot([2, 2], [2.0, 1.5], 'k-', linewidth=1)\n",
    "plt.text(2, 1.2, \"Create VPM + VPF\\nEmbed VPF in PNG\", fontsize=10, ha='center')\n",
    "\n",
    "# Draw decision storage\n",
    "plt.text(5, 2.5, \"Storage & Distribution\", fontsize=14, ha='center', fontweight='bold')\n",
    "plt.plot([4, 6], [2.0, 2.0], 'k-', linewidth=1)\n",
    "plt.plot([5, 5], [2.0, 1.5], 'k-', linewidth=1)\n",
    "plt.text(5, 1.2, \"Store as PNG\\nCDN/Object Storage\\nNo special handling\", fontsize=10, ha='center')\n",
    "\n",
    "# Draw decision verification\n",
    "plt.text(8, 2.5, \"Verification & Replay\", fontsize=14, ha='center', fontweight='bold', color='green')\n",
    "plt.plot([7, 9], [2.0, 2.0], 'g-', linewidth=2)\n",
    "plt.plot([8, 8], [2.0, 1.5], 'g--', linewidth=1)\n",
    "plt.text(8, 1.2, \"Extract VPF\\nVerify integrity\\nReproduce exactly\", fontsize=10, ha='center', color='green')\n",
    "\n",
    "# Draw arrows between steps\n",
    "plt.arrow(3.2, 1.7, 0.6, 0, head_width=0.1, head_length=0.1, fc='k', ec='k')\n",
    "plt.arrow(6.2, 1.7, 0.6, 0, head_width=0.1, head_length=0.1, fc='k', ec='k')\n",
    "\n",
    "plt.title(\"ZeroModel Provenance Workflow: From Creation to Verification\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c600948d",
   "metadata": {},
   "source": [
    "## 10. The Future: A New Standard for AI Trust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936a3d1",
   "metadata": {},
   "source": [
    "ZeroModel's provenance system represents a fundamental shift in how we establish trust in AI systems:\n",
    "\n",
    "- **Transparency by design**: The \"why\" is built into the artifact, not added later\n",
    "- **Verification at scale**: Check integrity by reading pixels, not running models\n",
    "- **Reproducibility as standard**: Run twice, get identical artifacts\n",
    "- **End-to-end traceability**: Follow reasoning chains across any number of steps\n",
    "\n",
    "This isn't just an improvement over current approaches - it's a complete rethinking of AI provenance that makes trust a built-in feature rather than an afterthought.\n",
    "\n",
    "The future of AI isn't just more powerful models - it's more trustworthy systems. And with ZeroModel, that future is already here."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
