============================= test session starts =============================
platform win32 -- Python 3.11.4, pytest-8.4.1, pluggy-1.6.0 -- C:\Users\ernan\Project\zeromi\venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\ernan\Project\zeromi
configfile: pyproject.toml
collecting ... collected 12 items

tests/test_core.py::test_normalization_quantization PASSED               [  8%]
tests/test_core.py::test_zeromodel_example PASSED                        [ 16%]
tests/test_core.py::test_duckdb_integration PASSED                       [ 25%]
tests/test_core.py::test_hierarchical_clustering PASSED                  [ 33%]
tests/test_core.py::test_tile_processing PASSED                          [ 41%]
tests/test_core.py::test_advanced_sql_queries PASSED                     [ 50%]
tests/test_core.py::test_metadata_handling FAILED                        [ 58%]
tests/test_core.py::test_performance_scalability SKIPPED (Temporaril...) [ 66%]
tests/test_core.py::test_hierarchical_navigation PASSED                  [ 75%]
tests/test_hierarchical_workflow.py::test_hierarchical_vpm_workflow PASSED [ 83%]
tests/test_workflow.py::test_complete_zeromodel_workflow PASSED          [ 91%]
tests/test_xor.py::test_xor_validation SKIPPED (Temporarily disablin...) [100%]

================================== FAILURES ===================================
___________________________ test_metadata_handling ____________________________

    def test_metadata_handling():
        """Test metadata extraction and usage across the system"""
        metric_names = ["uncertainty", "size", "quality", "novelty"]
        score_matrix = np.array([
            [0.8, 0.4, 0.9, 0.1],
            [0.6, 0.7, 0.3, 0.8],
            [0.2, 0.9, 0.5, 0.6],
            [0.9, 0.3, 0.2, 0.9]
        ])
    
        # Test ZeroModel metadata
        zeromodel = ZeroModel(metric_names, precision=10)
        zeromodel.set_sql_task("SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC")
    
        # MUST CALL PROCESS WITH DATA
        zeromodel.process(score_matrix) # This is where analysis for doc order should happen
    
        metadata = zeromodel.get_metadata()
        # ... assertions on metadata ...
        assert metadata["task"] == "sql_task"
        assert metadata["precision"] == 10
        assert metadata["metric_names"] == metric_names
        assert len(metadata["metric_order"]) == len(metric_names)
        assert len(metadata["doc_order"]) == score_matrix.shape[0]
    
        # Verify metric order metadata matches actual ordering
        for i in range(len(metadata["metric_order"]) - 1):
            # Earlier metrics should have higher weights in the SQL analysis
            assert metadata["metric_order"][i] < metadata["metric_order"][i+1]
    
        # Test HierarchicalVPM metadata
        hvpm = HierarchicalVPM(
            metric_names=metric_names,
            num_levels=3,
            zoom_factor=2,
            precision=8
        )
        hvpm.process(score_matrix, "SELECT * FROM virtual_index ORDER BY uncertainty DESC")
    
        metadata = hvpm.get_metadata()
        assert metadata["version"] == "1.0"
        assert metadata["levels"] == 3
        assert metadata["zoom_factor"] == 2
        assert metadata["task"] == "SELECT * FROM virtual_index ORDER BY uncertainty DESC"
        assert metadata["documents"] == score_matrix.shape[0]
        assert metadata["metrics"] == score_matrix.shape[1]
    
        # Test metadata across hierarchical levels
        for level in range(3):
            level_data = hvpm.get_level(level)
            level_metadata = level_data["metadata"]
    
            # Verify document and metric counts decrease with level
            if level > 0:
                prev_metadata = hvpm.get_level(level-1)["metadata"]
                # assert level_metadata["documents"] <= prev_metadata["documents"]
                # assert level_metadata["metrics"] <= prev_metadata["metrics"]
    
            # Verify sorted orders are valid
            assert len(level_metadata["sorted_docs"]) == level_metadata["documents"]
            assert len(level_metadata["sorted_metrics"]) == level_metadata["metrics"]
    
            # Verify sorted metrics are valid indices
            for idx in level_metadata["sorted_metrics"]:
                assert 0 <= idx < len(metric_names)
    
    
        # Test metadata with single metric
        single_metric = ZeroModel(["metric"])
        single_metric.set_sql_task("SELECT * FROM virtual_index ORDER BY metric DESC")
        single_metric.process(np.array([[0.8], [0.6], [0.2]]))
    
        metadata = single_metric.get_metadata()
        assert metadata["metric_names"] == ["metric"]
        assert len(metadata["metric_order"]) == 1
        assert metadata["metric_order"][0] == 0
    
        # Test metadata with no task set
        no_task = ZeroModel(metric_names)
>       no_task.process(score_matrix)

tests\test_core.py:565: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <zeromodel.core.ZeroModel object at 0x0000024E227841D0>
score_matrix = array([[0.8, 0.4, 0.9, 0.1],
       [0.6, 0.7, 0.3, 0.8],
       [0.2, 0.9, 0.5, 0.6],
       [0.9, 0.3, 0.2, 0.9]])

    def process(self, score_matrix: np.ndarray) -> None:
        """
        Process a score matrix to prepare for encoding.
        This involves loading the data into DuckDB and applying SQL-based organization.
    
        Args:
            score_matrix: 2D array of shape [documents × metrics]. Should be normalized.
        """
        logger.info(f"Processing score matrix of shape: {score_matrix.shape}")
        if score_matrix is None:
            error_msg = "score_matrix cannot be None."
            logger.error(error_msg)
            raise ValueError(error_msg)
        if score_matrix.ndim != 2:
            error_msg = f"score_matrix must be 2D, got shape {score_matrix.shape}."
            logger.error(error_msg)
            raise ValueError(error_msg)
        if score_matrix.shape[1] != len(self.metric_names):
            error_msg = (f"score_matrix column count ({score_matrix.shape[1]}) "
                        f"must match metric_names count ({len(self.metric_names)}).")
            logger.error(error_msg)
            raise ValueError(error_msg)
        if score_matrix.size == 0:
            logger.warning("Received empty score_matrix. Result will be empty.")
            self.sorted_matrix = np.empty((0, 0))
            self.metric_order = np.array([], dtype=int)
            self.doc_order = np.array([], dtype=int)
            return
    
        # --- Load data into DuckDB ---
        logger.debug("Loading score_matrix data into DuckDB virtual_index table.")
        try:
            # 1. Clear any existing data (including the initial test row)
            self.duckdb_conn.execute("DELETE FROM virtual_index")
    
            # 2. Prepare INSERT statement
            metric_columns = ", ".join([f'"{name}"' for name in self.metric_names])
            placeholders = ", ".join(["?"] * len(self.metric_names))
            insert_sql = f"INSERT INTO virtual_index (row_id, {metric_columns}) VALUES (?, {placeholders})"
    
            # 3. Insert data row by row
            # Using executemany might be more efficient for large datasets
            # data_for_db = [(i, *row) for i, row in enumerate(score_matrix)]
            # self.duckdb_conn.executemany(insert_sql, data_for_db)
            # For clarity and potential logging, inserting one by one or in small batches might be better initially
            for row_id, row_data in enumerate(score_matrix):
                # Ensure row_data is a list or tuple for DuckDB
                self.duckdb_conn.execute(insert_sql, [row_id] + row_data.tolist())
    
            logger.debug(f"Loaded {score_matrix.shape[0]} rows into DuckDB.")
        except Exception as e:
            logger.error(f"Failed to load data into DuckDB: {e}")
            raise ValueError(f"Error loading data into DuckDB: {e}") from e
    
        # --- Apply SQL-based spatial organization ---
        doc_order = None
        metric_order = None # Or default order if no specific reordering is derived
    
        if self.task_config and self.task_config.get("analysis"):
            logger.warning("task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.")
            # The analysis might have been done earlier, but now we have data.
            # We should re-run the analysis or adjust the logic.
            # Let's assume set_sql_task was called and we have the SQL query.
            sql_query = self.task_config.get("sql_query")
            if sql_query:
                logger.debug("Re-analyzing SQL task with data loaded.")
                analysis = self._analyze_query(sql_query) # This will now work on real data
                # _apply_sql_organization will use this analysis
                self.sorted_matrix, self.metric_order, self.doc_order = self._apply_sql_organization(
                    score_matrix, # Pass the original matrix
                    analysis
                )
            else:
                logger.error("SQL task set but no query found in task_config.")
                # Fall back to default
                self._apply_default_organization(score_matrix)
        elif self.task_config and self.task_config.get("sql_query"):
            # SQL task was set, but analysis wasn't run or stored correctly
            # Let's run analysis and apply organization now that data is loaded
            sql_query = self.task_config["sql_query"]
            logger.info(f"Applying SQL task: {sql_query} to loaded data.")
            try:
                analysis = self._analyze_query(sql_query)
                self.sorted_matrix, self.metric_order, self.doc_order = self._apply_sql_organization(
                    score_matrix, # Pass the original matrix
                    analysis
                )
            except Exception as e:
                logger.error(f"Failed to apply SQL task during processing: {e}")
                # Fall back to default organization
                self._apply_default_organization(score_matrix)
        else:
            logger.info("No SQL task set. Using default organization.")
>           self._apply_default_organization(score_matrix)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'ZeroModel' object has no attribute '_apply_default_organization'

zeromodel\core.py:363: AttributeError
------------------------------ Captured log call ------------------------------
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['uncertainty', 'size', 'quality', 'novelty'], precision: 10
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 4 metrics.
INFO     zeromodel.core:core.py:262 Setting SQL task: SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY uncertainty DESC, size ASC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'uncertainty' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:268 SQL task set. Analysis: {'doc_order': [0], 'metric_order': [0, 1, 2, 3], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'uncertainty', 'original_query': 'SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC'}
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (4, 4)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 4 rows into DuckDB.
WARNING  zeromodel.core:core.py:329 task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.
DEBUG    zeromodel.core:core.py:335 Re-analyzing SQL task with data loaded.
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY uncertainty DESC, size ASC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [3, 0, 1, 2]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'uncertainty' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:447 Applying SQL-based organization (with data). Data shape: (4, 4)
DEBUG    zeromodel.core:core.py:462 Final validated document order (first 10): [3, 0, 1, 2]...
DEBUG    zeromodel.core:core.py:481 Final validated metric order: [0, 1, 2, 3]
INFO     zeromodel.core:core.py:485 SQL-based organization (with data) applied. Final matrix shape: (4, 4)
DEBUG    zeromodel.core:core.py:365 Processing complete. Sorted matrix shape: (4, 4)
DEBUG    zeromodel.core:core.py:688 Retrieving metadata.
DEBUG    zeromodel.core:core.py:700 Metadata retrieved: {'task': 'sql_task', 'task_config': {'sql_query': 'SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC', 'analysis': {'doc_order': [0], 'metric_order': [0, 1, 2, 3], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'uncertainty', 'original_query': 'SELECT * FROM virtual_index ORDER BY uncertainty DESC, size ASC'}}, 'metric_order': [0, 1, 2, 3], 'doc_order': [3, 0, 1, 2], 'metric_names': ['uncertainty', 'size', 'quality', 'novelty'], 'precision': 10}
DEBUG    zeromodel.hierarchical:hierarchical.py:55 Initializing HierarchicalVPM with metrics: ['uncertainty', 'size', 'quality', 'novelty'], levels: 3, zoom: 2
INFO     zeromodel.hierarchical:hierarchical.py:80 HierarchicalVPM initialized with 3 levels.
INFO     zeromodel.hierarchical:hierarchical.py:93 Processing hierarchical VPM for task: 'SELECT * FROM virtual_index ORDER BY uncertainty DESC' with data shape (4, 4)
DEBUG    zeromodel.hierarchical:hierarchical.py:110 Updated metadata: documents=4, metrics=4
DEBUG    zeromodel.hierarchical:hierarchical.py:114 Cleared existing levels.
DEBUG    zeromodel.hierarchical:hierarchical.py:118 Creating base ZeroModel instance.
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['uncertainty', 'size', 'quality', 'novelty'], precision: 8
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 4 metrics.
INFO     zeromodel.core:core.py:262 Setting SQL task: SELECT * FROM virtual_index ORDER BY uncertainty DESC
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY uncertainty DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY uncertainty DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'uncertainty' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:268 SQL task set. Analysis: {'doc_order': [0], 'metric_order': [0, 1, 2, 3], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'uncertainty', 'original_query': 'SELECT * FROM virtual_index ORDER BY uncertainty DESC'}
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (4, 4)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 4 rows into DuckDB.
WARNING  zeromodel.core:core.py:329 task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.
DEBUG    zeromodel.core:core.py:335 Re-analyzing SQL task with data loaded.
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY uncertainty DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY uncertainty DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [3, 0, 1, 2]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'uncertainty' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:447 Applying SQL-based organization (with data). Data shape: (4, 4)
DEBUG    zeromodel.core:core.py:462 Final validated document order (first 10): [3, 0, 1, 2]...
DEBUG    zeromodel.core:core.py:481 Final validated metric order: [0, 1, 2, 3]
INFO     zeromodel.core:core.py:485 SQL-based organization (with data) applied. Final matrix shape: (4, 4)
DEBUG    zeromodel.core:core.py:365 Processing complete. Sorted matrix shape: (4, 4)
DEBUG    zeromodel.hierarchical:hierarchical.py:124 Base ZeroModel processed data.
DEBUG    zeromodel.hierarchical:hierarchical.py:254 Creating base level data structure (Level 2).
DEBUG    zeromodel.core:core.py:498 Encoding VPM...
DEBUG    zeromodel.core:core.py:505 Encoding matrix of shape 4x4
DEBUG    zeromodel.core:core.py:508 Calculated VPM width: 2 pixels
DEBUG    zeromodel.core:core.py:512 Created VPM image array of shape (4, 2, 3)
INFO     zeromodel.core:core.py:525 VPM encoded successfully. Shape: (4, 2, 3)
DEBUG    zeromodel.hierarchical:hierarchical.py:257 Encoded base level VPM image of shape (4, 2, 3).
DEBUG    zeromodel.hierarchical:hierarchical.py:274 Base level data structure created.
DEBUG    zeromodel.hierarchical:hierarchical.py:132 Base level (2) created and added.
DEBUG    zeromodel.hierarchical:hierarchical.py:140 Creating level 1 (relative 1)
DEBUG    zeromodel.hierarchical:hierarchical.py:145 Clustering to target size: docs=2, metrics=2
DEBUG    zeromodel.hierarchical:hierarchical.py:175 Clustering data of shape (4, 4) to 2 docs x 2 metrics.
DEBUG    zeromodel.hierarchical:hierarchical.py:181 Adjusted clustering targets: docs=2, metrics=2
DEBUG    zeromodel.hierarchical:hierarchical.py:202 Document cluster 0: rows 0-1 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:202 Document cluster 1: rows 2-3 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:215 Document clustering resulted in shape: (2, 4)
DEBUG    zeromodel.hierarchical:hierarchical.py:234 Metric cluster 0: cols 0-1 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:234 Metric cluster 1: cols 2-3 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:247 Metric clustering resulted in shape: (2, 2)
DEBUG    zeromodel.hierarchical:hierarchical.py:149 Clustered data shape: (2, 2)
DEBUG    zeromodel.hierarchical:hierarchical.py:282 Creating level data structure (Level 1).
DEBUG    zeromodel.hierarchical:hierarchical.py:288 Generated level metric names: ['cluster_0', 'cluster_1']
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['cluster_0', 'cluster_1'], precision: 8
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 2 metrics.
DEBUG    zeromodel.hierarchical:hierarchical.py:292 Created ZeroModel instance for this level.
DEBUG    zeromodel.hierarchical:hierarchical.py:301 Attempting to adapt base task query 'SELECT * FROM virtual_index ORDER BY uncertainty DESC' for level 1.
INFO     zeromodel.hierarchical:hierarchical.py:372 Could not reliably adapt base task ORDER BY for clustered level. Using default sorting by first cluster.
INFO     zeromodel.core:core.py:262 Setting SQL task: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'cluster_0' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:268 SQL task set. Analysis: {'doc_order': [0], 'metric_order': [0, 1], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'cluster_0', 'original_query': 'SELECT * FROM virtual_index ORDER BY cluster_0 DESC'}
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (2, 2)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 2 rows into DuckDB.
WARNING  zeromodel.core:core.py:329 task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.
DEBUG    zeromodel.core:core.py:335 Re-analyzing SQL task with data loaded.
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0, 1]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'cluster_0' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:447 Applying SQL-based organization (with data). Data shape: (2, 2)
DEBUG    zeromodel.core:core.py:462 Final validated document order (first 10): [0, 1]...
DEBUG    zeromodel.core:core.py:481 Final validated metric order: [0, 1]
INFO     zeromodel.core:core.py:485 SQL-based organization (with data) applied. Final matrix shape: (2, 2)
DEBUG    zeromodel.core:core.py:365 Processing complete. Sorted matrix shape: (2, 2)
DEBUG    zeromodel.hierarchical:hierarchical.py:391 Processed clustered data with level ZeroModel.
DEBUG    zeromodel.core:core.py:498 Encoding VPM...
DEBUG    zeromodel.core:core.py:505 Encoding matrix of shape 2x2
DEBUG    zeromodel.core:core.py:508 Calculated VPM width: 1 pixels
DEBUG    zeromodel.core:core.py:512 Created VPM image array of shape (2, 1, 3)
INFO     zeromodel.core:core.py:525 VPM encoded successfully. Shape: (2, 1, 3)
DEBUG    zeromodel.hierarchical:hierarchical.py:395 Encoded level 1 VPM image of shape (2, 1, 3).
DEBUG    zeromodel.hierarchical:hierarchical.py:412 Level 1 data structure created.
DEBUG    zeromodel.hierarchical:hierarchical.py:156 Level 1 created and added.
DEBUG    zeromodel.hierarchical:hierarchical.py:140 Creating level 0 (relative 2)
DEBUG    zeromodel.hierarchical:hierarchical.py:145 Clustering to target size: docs=1, metrics=1
DEBUG    zeromodel.hierarchical:hierarchical.py:175 Clustering data of shape (2, 2) to 1 docs x 1 metrics.
DEBUG    zeromodel.hierarchical:hierarchical.py:181 Adjusted clustering targets: docs=1, metrics=1
DEBUG    zeromodel.hierarchical:hierarchical.py:202 Document cluster 0: rows 0-1 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:215 Document clustering resulted in shape: (1, 2)
DEBUG    zeromodel.hierarchical:hierarchical.py:234 Metric cluster 0: cols 0-1 -> mean
DEBUG    zeromodel.hierarchical:hierarchical.py:247 Metric clustering resulted in shape: (1, 1)
DEBUG    zeromodel.hierarchical:hierarchical.py:149 Clustered data shape: (1, 1)
DEBUG    zeromodel.hierarchical:hierarchical.py:282 Creating level data structure (Level 0).
DEBUG    zeromodel.hierarchical:hierarchical.py:288 Generated level metric names: ['cluster_0']
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['cluster_0'], precision: 8
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 1 metrics.
DEBUG    zeromodel.hierarchical:hierarchical.py:292 Created ZeroModel instance for this level.
DEBUG    zeromodel.hierarchical:hierarchical.py:301 Attempting to adapt base task query 'SELECT * FROM virtual_index ORDER BY uncertainty DESC' for level 0.
INFO     zeromodel.hierarchical:hierarchical.py:372 Could not reliably adapt base task ORDER BY for clustered level. Using default sorting by first cluster.
INFO     zeromodel.core:core.py:262 Setting SQL task: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'cluster_0' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:268 SQL task set. Analysis: {'doc_order': [0], 'metric_order': [0], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'cluster_0', 'original_query': 'SELECT * FROM virtual_index ORDER BY cluster_0 DESC'}
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (1, 1)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 1 rows into DuckDB.
WARNING  zeromodel.core:core.py:329 task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.
DEBUG    zeromodel.core:core.py:335 Re-analyzing SQL task with data loaded.
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY cluster_0 DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'cluster_0' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:447 Applying SQL-based organization (with data). Data shape: (1, 1)
DEBUG    zeromodel.core:core.py:462 Final validated document order (first 10): [0]...
DEBUG    zeromodel.core:core.py:481 Final validated metric order: [0]
INFO     zeromodel.core:core.py:485 SQL-based organization (with data) applied. Final matrix shape: (1, 1)
DEBUG    zeromodel.core:core.py:365 Processing complete. Sorted matrix shape: (1, 1)
DEBUG    zeromodel.hierarchical:hierarchical.py:391 Processed clustered data with level ZeroModel.
DEBUG    zeromodel.core:core.py:498 Encoding VPM...
DEBUG    zeromodel.core:core.py:505 Encoding matrix of shape 1x1
DEBUG    zeromodel.core:core.py:508 Calculated VPM width: 1 pixels
DEBUG    zeromodel.core:core.py:512 Created VPM image array of shape (1, 1, 3)
INFO     zeromodel.core:core.py:525 VPM encoded successfully. Shape: (1, 1, 3)
DEBUG    zeromodel.hierarchical:hierarchical.py:395 Encoded level 0 VPM image of shape (1, 1, 3).
DEBUG    zeromodel.hierarchical:hierarchical.py:412 Level 0 data structure created.
DEBUG    zeromodel.hierarchical:hierarchical.py:156 Level 0 created and added.
INFO     zeromodel.hierarchical:hierarchical.py:161 Hierarchical VPM processing complete.
DEBUG    zeromodel.hierarchical:hierarchical.py:525 Retrieving hierarchical VPM metadata.
DEBUG    zeromodel.hierarchical:hierarchical.py:536 Hierarchical VPM metadata retrieved.
DEBUG    zeromodel.hierarchical:hierarchical.py:428 Retrieving data for level 0.
DEBUG    zeromodel.hierarchical:hierarchical.py:437 Level 0 data retrieved.
DEBUG    zeromodel.hierarchical:hierarchical.py:428 Retrieving data for level 1.
DEBUG    zeromodel.hierarchical:hierarchical.py:437 Level 1 data retrieved.
DEBUG    zeromodel.hierarchical:hierarchical.py:428 Retrieving data for level 0.
DEBUG    zeromodel.hierarchical:hierarchical.py:437 Level 0 data retrieved.
DEBUG    zeromodel.hierarchical:hierarchical.py:428 Retrieving data for level 2.
DEBUG    zeromodel.hierarchical:hierarchical.py:437 Level 2 data retrieved.
DEBUG    zeromodel.hierarchical:hierarchical.py:428 Retrieving data for level 1.
DEBUG    zeromodel.hierarchical:hierarchical.py:437 Level 1 data retrieved.
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['metric'], precision: 8
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 1 metrics.
INFO     zeromodel.core:core.py:262 Setting SQL task: SELECT * FROM virtual_index ORDER BY metric DESC
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY metric DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY metric DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'metric' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:268 SQL task set. Analysis: {'doc_order': [0], 'metric_order': [0], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'metric', 'original_query': 'SELECT * FROM virtual_index ORDER BY metric DESC'}
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (3, 1)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 3 rows into DuckDB.
WARNING  zeromodel.core:core.py:329 task_config.analysis found, but data is now in DuckDB. Re-analyzing based on DuckDB query results.
DEBUG    zeromodel.core:core.py:335 Re-analyzing SQL task with data loaded.
DEBUG    zeromodel.core:core.py:373 Analyzing SQL query with data: SELECT * FROM virtual_index ORDER BY metric DESC
DEBUG    zeromodel.core:core.py:389 Executing modified query for analysis: SELECT row_id FROM virtual_index ORDER BY metric DESC
DEBUG    zeromodel.core:core.py:397 Document order determined by DuckDB query execution: [0, 1, 2]...
DEBUG    zeromodel.core:core.py:413 Primary sort metric identified from query: 'metric' (index 0)
INFO     zeromodel.core:core.py:426 SQL query analysis (with data) complete.
DEBUG    zeromodel.core:core.py:447 Applying SQL-based organization (with data). Data shape: (3, 1)
DEBUG    zeromodel.core:core.py:462 Final validated document order (first 10): [0, 1, 2]...
DEBUG    zeromodel.core:core.py:481 Final validated metric order: [0]
INFO     zeromodel.core:core.py:485 SQL-based organization (with data) applied. Final matrix shape: (3, 1)
DEBUG    zeromodel.core:core.py:365 Processing complete. Sorted matrix shape: (3, 1)
DEBUG    zeromodel.core:core.py:688 Retrieving metadata.
DEBUG    zeromodel.core:core.py:700 Metadata retrieved: {'task': 'sql_task', 'task_config': {'sql_query': 'SELECT * FROM virtual_index ORDER BY metric DESC', 'analysis': {'doc_order': [0], 'metric_order': [0], 'primary_sort_metric_index': 0, 'primary_sort_metric_name': 'metric', 'original_query': 'SELECT * FROM virtual_index ORDER BY metric DESC'}}, 'metric_order': [0], 'doc_order': [0, 1, 2], 'metric_names': ['metric'], 'precision': 8}
DEBUG    zeromodel.core:core.py:45 Initializing ZeroModel with metrics: ['uncertainty', 'size', 'quality', 'novelty'], precision: 8
INFO     zeromodel.core:core.py:61 ZeroModel initialized with 4 metrics.
INFO     zeromodel.core:core.py:278 Processing score matrix of shape: (4, 4)
DEBUG    zeromodel.core:core.py:300 Loading score_matrix data into DuckDB virtual_index table.
DEBUG    zeromodel.core:core.py:319 Loaded 4 rows into DuckDB.
INFO     zeromodel.core:core.py:362 No SQL task set. Using default organization.
=========================== short test summary info ===========================
FAILED tests/test_core.py::test_metadata_handling - AttributeError: 'ZeroMode...
=================== 1 failed, 9 passed, 2 skipped in 1.58s ====================
